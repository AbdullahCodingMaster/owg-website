---
layout: post
title:  "November 2016"
date: 2016-11-30 23:59:59
---

# Outage 2016-11-02

Index rebuild caused the PostgreSQL replicas to lag behind the master. This caused issues with "stale reads" against the API and contributors getting edit conflicts.

It is anticipated that index rebuilds will not take as long in the future, as there will be less to rebuild. Also, the move to NVMe-based servers will increase the I/O capacity, meaning that this sort of maintenance will be less disruptive.

# Added disks in services server

Added two extra disks to the services server, [ironbelly](https://hardware.openstreetmap.org/servers/ironbelly.openstreetmap.org/). This was necessary to increase storage space available for backups, planet files, replication files and Rails assets. [Issue](https://github.com/openstreetmap/operations/issues/116).

# Outage 2016-11-04

In order to increase the capacity of the services server, [ironbelly](https://hardware.openstreetmap.org/servers/ironbelly.openstreetmap.org/), two extra disks were added. After being added, the disks must be incorporated into the RAID array to be useful. The server supports an "online" rebuild with no downtime, so that was used. However, this meant that other accesses to the disk were very slow and this lead to failures on machines which had the services machine mounted as a remote filesystem, which included the web servers.

OWG has been discussing migrating the Rails storage function off the services server and onto a distributed filesystem. This work is not ready yet, but it is anticipated that something like it will reduce dependence on the services server.

# Failed RAID battery in forum server

The forum server, [clifford](https://hardware.openstreetmap.org/servers/clifford.openstreetmap.org/), had a failed RAID battery. This was replaced with a Flash-backed Write Cache, which should be more durable. [Issue](https://github.com/openstreetmap/operations/issues/110).

