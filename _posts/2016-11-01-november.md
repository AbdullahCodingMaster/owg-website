---
layout: post
title:  "November 2016"
date: 2016-11-30 23:59:59
---

# Replication Delays 2nd November

On 2nd November there were delays replicating the main database due to index rebuilding on the master server Katla. This lead to some confusion where mappers were successfully saving their changes, but not seeing the results when making subsequent map calls. The problem resolved itself a few hours later. The blocking of replication during certain stages of the index rebuilding was unexpected.

It is anticipated that index rebuilds will not take as long in the future, as there will be less to rebuild. Also, the move to NVMe-based servers will increase the I/O capacity, meaning that this sort of maintenance will be less disruptive.

# Added disks in services server

Added two extra disks to the services server, [ironbelly](https://hardware.openstreetmap.org/servers/ironbelly.openstreetmap.org/). This was necessary to increase storage space available for backups, planet files, replication files and Rails assets. [Issue](https://github.com/openstreetmap/operations/issues/116).

# Site outage 4th November

In order to increase the capacity of the services server, [ironbelly](https://hardware.openstreetmap.org/servers/ironbelly.openstreetmap.org/), two extra disks were added. After being added, the disks must be incorporated into the RAID array to be useful. The server supports an "online" rebuild with no downtime, so that was used. However, the machine became overloaded. Services that depend on ironbelly, notably the web frontends and rails backends for NFS mounts, were affected. Service was recovered by suspending non-critical tasks on ironbelly and slowing the rate of RAID rebuiding.

OWG has been discussing migrating the Rails storage function off the services server and onto a distributed filesystem. This work is not ready yet, but it is anticipated that something like it will reduce dependence on the services server.

# Failed RAID battery in forum server

The forum server, [clifford](https://hardware.openstreetmap.org/servers/clifford.openstreetmap.org/), had a failed RAID battery. This was replaced with a Flash-backed Write Cache, which should be more durable. [Issue](https://github.com/openstreetmap/operations/issues/110).

# Failed disk in dev server

The development and testing server, [errol](https://hardware.openstreetmap.org/servers/errol.openstreetmap.org/), had a disk which indicated failure. An attempt was made to replace it, but then it hung on boot. In case the issue was with the disk, the bad one was returned, but the error didn't clear. It turned out that the error was the file system requiring an extraordinarily long time to replay the journal log. This required some downtime while waiting for the file system to come back online. Another attempt will be made to replace the pre-fail disk. [Issue](https://github.com/openstreetmap/operations/issues/118).

# Recover overwritten old minutely diffs

User `mmd-osm` noticed that some of the oldest minutely diffs had been overwritten, perhaps due to file system corruption issues resetting the config for `osmosis` replication. Thankfully, `mmd-osm` was also able to provide archived copies of those diffs and they have now been restored. [Issue](https://github.com/openstreetmap/operations/issues/121).

# Extra disks for ridley, urmel

Extra disks were added to the Foundation websites server, [ridley](https://hardware.openstreetmap.org/servers/ridley.openstreetmap.org/), and Munin server, [urmel](https://hardware.openstreetmap.org/servers/urmel.openstreetmap.org/). These mean increased redundancy on the servers, and less chance that urgent maintenance will be needed.
